# 2.6 Integridade & Metadados (Proveniência como Primeiro Cidadão)

A Z2 não é só um grande “HD barato”; é o **registro histórico oficial** de tudo o que foi ingerido com sucesso pela Z1.

Se a Z2 é a base dos seus modelos e dos seus relatórios críticos, você precisa responder — sem gaguejar — às perguntas:

* **De onde veio esse dado?**
* **Quem mandou? Por qual pipeline? Quando?**
* **Esse arquivo é exatamente o mesmo que eu usei pra treinar o modelo?**
* **Alguém alterou algo depois? Conseguimos provar que não?**

Princípio central:

> **Cada objeto em Z2 carrega consigo evidências de integridade e proveniência.
> Sem metadados confiáveis, não existe confiança nos modelos.**

---

## 2.6.1 O que é “Integridade” na Z2

Integridade em Z2 significa:

1. **O conteúdo não foi alterado sem registro.**
2. **Se algo mudar, eu consigo perceber e rastrear.**
3. **Consigo provar que os dados usados em decisões/modelos são os mesmos que foram ingeridos.**

Ferramentas básicas:

* Hashes criptográficos (ex.: **SHA-256**),
* Assinaturas digitais (quando necessário),
* Metadados estruturados,
* Logs e versionamento (2.5) como reforço.

---

## 2.6.2 Metadados obrigatórios de proveniência

Cada arquivo/objeto na Raw Zone deve conter (no próprio objeto ou em catálogo associado) um conjunto mínimo de metadados padrão.

Recomendações:

* **Identidade da origem**

  * `source_system`: ex. `core-transacoes`, `parceiro-x`, `open-finance`.
  * `source_type`: `INTERNAL`, `PARTNER`, `PUBLIC`.
  * `ingestion_endpoint`: ex. `/ingest/transacoes/v1`.

* **Pipeline responsável**

  * `ingestion_pipeline`: ex. `airflow_dag_ingest_core_tx_v3`.
  * `connector_id`: serviço ou job que gravou (service account).

* **Carimbo de tempo**

  * `ingestion_time`: quando chegou em Z2.
  * `event_time` (se aplicável): quando o evento/dado ocorreu.

* **Esquema & versão**

  * `schema_id` ou `schema_version`: mapeado ao contrato de dados (Z0/Z1).
  * permite saber com qual layout aquele dado foi validado.

* **Classificação & Sensibilidade**

  * `data_classification`: `public`, `internal`, `confidential`, `restricted`, `pii`, `secret`.
  * ajuda Z3/Z8 a aplicar políticas de mascaramento, DLP, etc.

* **Integridade**

  * `content_hash`: SHA-256 (ou similar) do arquivo/lote.
  * (opcional) `signature`:

    * assinatura com chave privada ou KMS (2.2) do hash ou do manifesto.

Esses metadados podem ser:

* armazenados como **metadata do objeto** (S3/MinIO),
* ou em um **catálogo** (Z8 — Data Catalog),
* ou em um **manifest** (JSON/YAML) versionado junto com os dados.

---

## 2.6.3 Hashes & Assinaturas (como garantir que ninguém mexeu)

**Hashes criptográficos**

* Para cada arquivo/lote em Z2:

  * calcular `SHA-256` (ou SHA-512, BLAKE2, etc.),
  * registrar no metadado ou catálogo.
* Ao consumir:

  * recalcular hash,
  * comparar com o registrado.
* Se diferente → alerta: dado corrompido ou alterado.

**Assinaturas digitais (opcional, forte)**

* Em cenários de alta segurança:

  * o conector oficial (Z1/Z4) envia o hash para ser assinado por uma chave no **KMS/Vault**.
  * a **assinatura** é armazenada junto ao objeto.
* Na leitura:

  * valida a assinatura via chave pública / KMS.
* Garante:

  * integridade,
  * autenticidade da origem (só quem possui a chave privada poderia ter gerado aquela assinatura).

Isso é ouro para:

* evitar manipulação interna maliciosa,
* dar garantias fortes para auditorias e reguladores,
* compor uma trilha de confiança para os modelos (Z4/Z5).

---

## 2.6.4 Conectando Z1 → Z2: trilha ponta a ponta

Z1 já registra:

* quem chamou,
* qual `client_id`,
* qual endpoint,
* qual hash/arquivo foi aceito,
* qual `request_id`/`correlation_id`.

Z2 registra:

* o mesmo hash,
* a mesma origem,
* o pipeline que gravou,
* o timestamp.

Juntando:

> Você consegue pegar um arquivo em Z2 e voltar até a chamada original da Z1 que o gerou.

Exemplo mental:

1. Requisição `request_id=abc123` de `client_id=parceiro-x` para `/ingest/score`.
2. Passa na Z1, gera:

   * `content_hash = SHA-256: 0xDEADBEEF...`
   * loga: `source_system=parceiro-x`, `result=ACCEPTED`, `request_id=abc123`.
3. Conector oficial grava em:

   * `raw/parceiro-x/score/year=2025/.../part-0001.parquet`
   * com metadados:

     * `source_system=parceiro-x`
     * `ingestion_pipeline=airflow_ingest_parceiro_x_v2`
     * `ingestion_time=2025-11-10T10:00:00Z`
     * `content_hash=0xDEADBEEF...`
4. Qualquer consumo futuro pode:

   * recalcular o hash,
   * bater com o hash logado em Z1/Z9,
   * provar que é o mesmo conteúdo aprovado na borda.

---

## 2.6.5 Uso de Metadados na Jornada de Dados & Modelos

Esses metadados não são só “enfeite”. Eles alimentam:

1. **Z3 — Curated & Feature Store**

   * Consegue saber:

     * de quais fontes ler,
     * com quais versões de schema,
     * quais dados são sensíveis (para mascarar/anonimizar).

2. **Z4 — Model Factory**

   * Ao treinar um modelo:

     * registrar quais `content_hash`/partições de Raw/Curated foram usadas.
   * Depois:

     * se surgir um problema (fraude, bug), dá pra:

       * localizar os arquivos de origem,
       * verificar integridade,
       * refazer o treino.

3. **Z5 — Model Registry & Governance**

   * Guardar no registro do modelo:

     * referência às versões de datasets (hashes, paths, datas),
     * isso viabiliza **reproducibilidade e explicabilidade**.

4. **Z8 / Z9 — Segurança & Auditoria**

   * Correlacionar:

     * uso de dados sensíveis,
     * acesso a objetos críticos,
     * mudanças de integridade.

---

## 2.6.6 Erros clássicos (pra você citar como “não faremos”)

* Não salvar **nenhum** metadado além do nome do arquivo.
* Usar nomes de arquivo aleatórios sem contexto de fonte/tempo.
* Não calcular hash (ou usar MD5 só “por costume”).
* Não ter vínculo entre logs de ingestão (Z1) e objetos em Z2.
* Misturar dados de múltiplas fontes/dominios na mesma pasta sem identificar.

Tudo isso mata:

* rastreabilidade,
* reprodutibilidade,
* capacidade de provar integridade.

---

## 2.6.7 Alinhamento com Frameworks & Riscos

**Frameworks**

* **NIST SP 800-53**

  * SI-7: *Software, Firmware, and Information Integrity*.
  * AU-3/AU-8/AU-9: integridade e proteção de trilhas de auditoria.
* **CSA CCM / CSA AICM**

  * Controles de data lineage, data integrity, traceability.
* **Práticas de IA responsável**

  * Requisito de **proveniência dos dados de treino** (NIST AI RMF, EU AI Act, etc.).

**Riscos mitigados (ligando à seção 3 de Z2)**

* 3.2 — Alteração não autorizada (detecção por hash/assinatura/versionamento).
* 3.5 — Shadow pipelines (metadados + logs evidenciam quem escreveu).
* 3.6 — Falta de proveniência (cada objeto sabe de onde veio).
* 3.7 — Modelos treinados em dados errados/ilegais (você consegue checar).
