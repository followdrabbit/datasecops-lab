# Z3-2.8 — Logging, Observabilidade & Drift de Dados

**se você não mede, você não governa; se não loga, você não investiga; se não monitora, seu modelo “apodrece” em silêncio**

Na Z3, você já tem **dado curado, classificado e transformado em features**. Agora precisa garantir duas coisas:

1. **Ninguém usa nem altera isso sem você saber** (segurança & auditoria).
2. **As distribuições não “andam” em silêncio** (data/feature/label drift, degradação do modelo).

Z3-2.8 torna a camada curada/Feature Store um **sensor de integridade e de comportamento** para toda a plataforma, alimentando a Z9.

Princípio central:

> **Z3 não é só fonte de dados; é um subsistema de detecção precoce.
> Ela observa a si mesma, observa quem a consome e avisa quando o mundo mudou.**

---

## 1) Objetivos

Três eixos principais:

1. **Auditabilidade**
   Traçar “quem leu o quê, quando, de onde, usando qual identidade” em todos os datasets/feature stores de Z3.

2. **Saúde do dado curado & das features**
   Medir e acompanhar continuamente:

   * freshness (atrasos),
   * volume,
   * qualidade (nulls, duplicados, erros),
   * distribuições (drift de entrada),
   * correlação com labels (drift de performance).

3. **Detecção de ameaças a dados & modelos**

   * Data poisoning “sutil”,
   * manipulação de features,
   * exfiltração via consultas maliciosas,
   * uso indevido de PII ou features sensíveis.

Alinhado com:
**OWASP Top 10 — A09: Security Logging & Monitoring Failures** (sem log não há detecção)
**NIST SP 800-53 Rev.5 — AU-2/6/9, SI-4** (log, análise, monitoramento contínuo)
**NIST AI RMF** — governança + monitoramento contínuo de dados/modelos.
**OWASP ML Top 10** — especialmente ML02 (Data Poisoning), ML09 (Output Integrity), ML10 (Model Poisoning).

---

## 2) O que logar em Z3 (audit trail de dado e feature)

Se na Z2 você loga o acesso ao **cofre bruto**, em Z3 você loga o acesso ao **que de fato decide crédito, fraude, limites, ofertas**.

### 2.1 Eventos de Acesso a Datasets Curados

Para cada acesso relevante (read/write):

* `actor_id` / `service_account` / usuário humano.
* `auth_context`:

  * client_id, roles, grupos, atributos ABAC (ex.: `domain=risco`).
* `resource`:

  * dataset/view/feature_group (`curated_risco_transacoes_v2`, `fs_offline.risco_cliente_v1`).
* `operation`:

  * `SELECT`, `INSERT`, `UPDATE`, `DELETE`, `CREATE VIEW`, `ALTER TABLE`.
* `scope`:

  * linhas estimadas lidas,
  * colunas sensíveis acessadas (`pii=true`, `restricted`).
* `outcome`:

  * `success` / `denied` / `error`,
  * motivo da negação.

### 2.2 Eventos de Pipelines & Transformações

Cada execução de pipeline em Z3 deve gerar logs/metadata:

* `pipeline_id`, `dag_run_id`, `task_id`.
* `code_version` (`git_sha`, tag).
* `input_datasets` (Z2/Z3) + `input_hashes`.
* `output_datasets`/feature groups + partições geradas.
* Resultado de **DQ (Z3-2.3)**:

  * `% linhas aprovadas`,
  * regras que falharam,
  * `dq_status` (PASS/WARN/FAIL).

### 2.3 Eventos de Configuração & Políticas

Logar sempre que alguém:

* altera schema de dataset curado/feature group,
* muda classificação de coluna (ex.: tira `pii=true`),
* modifica política de acesso (RBAC/ABAC, RLS/CLS),
* mexe em pipelines oficiais de curadoria/feature engineering.

Esses eventos são críticos pra **forense e compliance**.

---

## 3) Métricas de Observabilidade de Dados & Features

Além de logs, Z3 precisa publicar métricas contínuas para a Z9.

### 3.1 Freshness & Latência

Para cada dataset/feature group:

* **“idade” do último lote**:

  * diferença entre `now()` e `max(event_timestamp)` ou `produced_at`.
* Limites:

  * ex.: `dp_risco_score_cliente_v1` deve estar atualizado há no máximo 15 minutos.
* Alertas:

  * se estourar o SLA → alerta para Data Eng / SRE / MLOps.

### 3.2 Volume & Completude

* Linhas geradas por janela (ex.: dia, hora),
* Taxa de:

  * registros descartados,
  * nulos por coluna crítica,
  * linhas fora de schema.
* Alertas:

  * queda brusca (ex.: 80% menos eventos),
  * explosão suspeita (ex.: 5x mais eventos em poucos minutos).

### 3.3 Distribuição & Data Drift (Input Drift)

Para atributos-chave (features e colunas críticas):

* Estatísticas:

  * média, mediana, desvio, quantis, histograma.
* Comparação:

  * com janelas históricas (ex.: últimos 7/30 dias).
* Alertas:

  * se `population_stability_index (PSI)` ou `KL divergence` passar de limiar,
  * se surgirem valores impossíveis/raros demais.

### 3.4 Label Drift & Performance Drift

Pra modelos em produção (Z4/Z6), Z3 monitora:

* Distribuição dos **labels** ao longo do tempo,
* Diferença entre:

  * performance offline (validação),
  * performance online (realidade).
* Alertas:

  * queda significativa em AUC/KS/Recall,
  * mudança brusca na taxa de aprovação/negativa.

Isso é diretamente recomendado pelo **NIST AI RMF** (monitorar desempenho e impacto ao longo do ciclo de vida).

---

## 4) Z3 como sensor de ameaças (Drift, Poisoning, Uso Indevido)

Aqui entra o “mindset de segurança” aplicado a dados e modelos.

### 4.1 Data Poisoning & Ataques silenciosos

Se um atacante injeta dados “plausíveis” na entrada (Z0/Z1/Z2), o primeiro lugar onde isso aparece de forma estruturada é na **Z3**.

Sinais a monitorar:

* aumento anômalo de registros com certos padrões:

  * um único CPF com milhares de transações pequenas,
  * muitos registros com o mesmo IP/dispositivo,
* alterações súbitas em distribuições de features usadas por modelos,
* surgimento de valores “craftados” (ex.: payloads com padrões específicos).

Ação:

* marcar lotes como suspeitos,
* bloquear promoção para Feature Store,
* abrir incidente,
* rastrear pela lineage (Z3-2.4) até a origem em Z2/Z1/Z0.

Conexão com **OWASP ML Top 10 — ML02 (Data Poisoning)**.

### 4.2 Abuso & Exfiltração de Dados

Monitorar uso dos Data Products e Feature Store para identificar:

* Consultas que:

  * varrem tabela inteira,
  * focam apenas em colunas PII sensíveis,
  * fogem do padrão histórico de acesso.
* Serviços que:

  * passam a ler muito mais features do que o normal,
  * ou começam a acessar datasets fora do seu domínio.

Ação:

* Alertar SOC,
* aplicar **rate limiting / bloqueio** (integração com Z8/Z6),
* revisão de credenciais e policies.

Endereça **OWASP A09 (Logging & Monitoring)** e **NIST AU-6/SI-4 (monitoramento e resposta a incidentes)**.

### 4.3 Output Integrity & Model Misuse

Z3 também ajuda a checar se as saídas (scores, recomendações) continuam coerentes com os dados de entrada:

* Comparar:

  * distribuição dos scores ao longo do tempo,
  * relação entre score e eventos reais (default, fraude, etc.).
* Alertar:

  * se modelo “travou” (só gera 0.99),
  * se alguém está manipulando features/outputs no caminho (ML09 — Output Integrity).

---

## 5) Integração com Z9 — Como tudo se conecta

Z3 **não precisa virar um SIEM**; ela precisa **emitir eventos ricos**.

Fluxo típico:

1. **Z3 gera logs estruturados & métricas**

   * Acessos, DQ, drift, lineage, políticas.
2. **Z9 (Monitoring & Audit) recebe**

   * via:

     * Loki/ELK/OpenSearch + Prometheus/Grafana,
     * ou SIEM corporativo.
3. **Z9 correlaciona**

   * Logs da Z1 (ingestão & WAF) + Z2 (storage) + Z3 (curadoria/features) + Z4/Z5/Z6 (modelos & APIs) + Z8 (IAM/Vault).
4. **Geração de alertas & evidências**

   * Dashboards:

     * Saúde de datasets/feature groups,
     * Mapa de dependências com status,
     * Acessos a PII por role.
   * Playbooks:

     * “Se DQ falhar em dataset crítico → pausar DAG de treino + notificar time.”
     * “Se exfiltração suspeita em Z3 → bloquear tokens no IdP/Vault + isolar serviço.”

---

## 6) Implementação no MLOps Security Lab (prático)

Você consegue demonstrar isso de forma enxuta e poderosa:

1. **Logs Estruturados**

   * Configurar:

     * Airflow para logar JSON com run_id, dataset, DQ_status.
     * DB/MinIO para emitir logs de acesso (já vimos em Z2.8).
   * Padronizar `correlation_id` vindo da Z1.

2. **Métricas de DQ & Freshness**

   * Expor via Prometheus:

     * `dataset_freshness_seconds{dataset="curated_risco_transacoes_v2"}`
     * `dq_failures_total{dataset="curated_risco_transacoes_v2"}`
   * Dashboards no Grafana.

3. **Drift Detection Simples**

   * Script diário:

     * lê features chave,
     * calcula média/PSI,
     * grava métrica + log,
     * dispara alerta se passar do limiar.

4. **Auditoria de Acesso**

   * Logar todas as queries feitas em datasets/Feature Store sensíveis,
   * Enviar para um índice dedicado no stack de logs,
   * Mostrar consultas de exemplo:

     * “quem acessou `curated_clientes_restrito` nas últimas 24h?”.

5. **Documentar no README**

   * Seção “Z3 como sensor de segurança & qualidade”,
   * Com exemplos de:

     * JSON de log,
     * gráfico de freshness,
     * alerta de drift.

---

## 7) Riscos mitigados (amarrando com Z3 Seção 3)

Z3-2.8 é o “cinto de segurança + airbag” dos riscos já mapeados:

* **3.1 — Garbage In / Garbage Model**
  → DQ contínua + métricas + alertas.
* **3.2 — Vazamento de PII**
  → logs de acesso, DLP, auditoria fina.
* **3.3 — Leakage & uso indevido de features**
  → monitoramento de quem lê o quê.
* **3.4 — Bypass da Z3/Z2**
  → logs deixam claro quem acessou fora dos data products oficiais.
* **3.5 — Falta de transparência**
  → lineage + eventos de pipeline + métricas compartilhadas.
* **3.6 — Supply chain / Poisoning / Output Integrity**
  → drift, DQ, correlação fim-a-fim entre origem de dados, features, modelos e outputs.
