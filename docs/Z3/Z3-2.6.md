# Z3-2.6 — Feature Store (Offline & Online)

**onde o dado curado vira feature confiável para treino e predição — com segurança de supply chain**

A **Feature Store** é o ponto de encontro entre Z3 (dado curado) e Z4/Z6 (modelos e inferência).
Sem ela, cada squad inventa suas próprias transformações, repete bugs, vaza PII sem perceber e cria *train/serving skew* na mão.

Com ela, você tem:

* **Um catálogo único de features** (atributos prontos para uso) com dono, definição, versionamento e testes.
* **Uma fonte de verdade consistente** para:

  * treino (offline),
  * inferência em produção (online),
  * sem reimplementar lógica em cada microserviço.
* **Camada de segurança e governança** para evitar:

  * data poisoning via features,
  * uso indevido de PII como sinal,
  * divergência entre treino e produção,
  * supply chain maliciosa (ML06, ML10 do OWASP ML).

Princípio central:

> **Feature não é uma coluna solta: é um produto governado.
> Só existe feature “oficial” se nasce da Z3 curada, passa por DQ, é versionada, assinada e servida por canais seguros.**

---

## 1) Papéis da Feature Store em Z3

A Z3-2.6 é composta por duas faces complementares:

1. **Offline Feature Store**

   * Tabelas/arquivos de features históricas, derivadas da Curated Zone (Z3-2.1).
   * Usadas para treino, validação e re-treino (Z4).
   * Garantem *time-travel*, *point-in-time correctness* e reprodutibilidade.

2. **Online Feature Store**

   * Serviço de baixa latência (key-value / banco de features) para leitura em tempo real.
   * Alimenta **Z6 — Model Serving & Inference** com os mesmos cálculos do offline.
   * Exposta via APIs seguras (mTLS + AuthN/AuthZ via Z8 + audit Z9).

**Regra de ouro:**

* Features **sempre derivadas de Z3 (Curated)** ou de **modelos aprovados (Z5)**.
* Nada de “microserviço do squad X calculando feature na régua dele direto da Z2”.

---

## 2) Arquitetura Conceitual

### 2.1 Offline Feature Store

* Armazenada em:

  * Data Warehouse / Lakehouse interno (Postgres/ClickHouse/Parquet em MinIO).
* Estrutura típica:

  * **Feature Groups**:

    * `fs_offline.risco_cliente_v1`
    * `fs_offline.fraude_transacao_v2`
  * Chaves:

    * `entity_id` (ex.: `customer_id`, `account_id`, `device_id`),
    * `event_timestamp`,
    * `feature_name` / colunas fixas.
* Regras:

  * Só consome dados de Z3 Curated (nunca direto de Raw, salvo exceções justificadas e auditadas).
  * Cada carga de features:

    * é um pipeline versionado,
    * tem DQ (Z3-2.3),
    * tem manifest + lineage (Z3-2.4),
    * registra qual **schema / código / origem** gerou aquele snapshot.

### 2.2 Online Feature Store

* Implementada como:

  * banco KV/colunar de baixa latência (ex.: Redis, DynamoDB, Cassandra, Postgres otimizado, ou mesmo serviço interno em memória),
  * acessado via **API/SDK oficial**.
* Características:

  * Leitura por chave (`get_feature_vector(customer_id)`),
  * Baixa latência (ms-level),
  * Sincronização automatizada com a Offline Store:

    * via jobs de materialização incremental,
    * evitando divergência de lógica.
* Rede & segurança:

  * exposta **apenas dentro de Z6**, atrás do **Inference Gateway**,
  * acesso via **mTLS**, **service accounts** e **ABAC** (Z8),
  * todos os acessos logados em Z9.

---

## 3) Governança de Features (Feature = Produto)

Cada feature (ou grupo de features) na Z3 tem metadados formais, assim como um dataset curado:

**Para cada Feature Group:**

* `name`: `fs_offline.risco_cliente_v1`
* `description`: “Features de risco de crédito por cliente (janelas 7/30/90 dias)”
* `domain`: `risco`
* `owner`: time responsável (ex.: Risk Analytics)
* `entity`: `customer_id`
* `ttl`:

  * ex.: 24h para online,
  * define a validade do valor em produção.
* `source_datasets`:

  * links para `curated_risco_transacoes_v2`, `curated_clientes_v3`, etc.
* `transformation_code_ref`:

  * `git_sha`, versão do DAG/pipeline.
* `schema`:

  * colunas + tipos + descrições + sensibilidade.
* `sensitivity`:

  * por feature:

    * ex.: `avg_ticket_30d` (confidential),
    * `pep_flag` (restricted),
    * `device_id_hash` (pii/pseudonimized).

**Esses metadados são registrados no:**

* **Schema Registry (Z3-2.2)**,
* **Data Catalog (Z3-2.4)**,
* e vinculados ao **Model Registry (Z5)**:

  * cada modelo lista as features e versões utilizadas.

---

## 4) Segurança da Feature Store (linha dura, estilo banco)

Aqui é onde você brilha como Eng. MLOps + Sec:

### 4.1 Só escreve quem deve escrever

* Produção de features:

  * feita por **pipelines oficiais** (Airflow, Spark, Flink, jobs com service accounts).
  * policies:

    * `svc-feature-risco-v1` pode **write** apenas em `fs_offline.risco_cliente_v1`.
    * nada de `INSERT` manual via analista.
* Fonte obrigatória:

  * inputs vêm de **Z3 Curated** (já com DQ & PII tratada),
  * ou saídas de modelos aprovados (Z5) com assinatura verificada.

Mitiga:

* **ML02/ML10 — Data/Model Poisoning**: reduz chance de alguém injetar feature maliciosa manualmente.

### 4.2 Só lê quem pode ler (ABAC sobre features)

* Autenticação:

  * via IdP (Z8), mTLS, JWT/OIDC, service accounts.
* Autorização:

  * **por feature group e até por coluna**:

    * ex.: `api_risco_credito` só pode ler features `score_risco`, `avg_ticket_30d`, não `pep_flag` se não houver base legal.
* ABAC guiado pelo catálogo:

  * se `feature.sensitivity = restricted`:

    * só roles específicas podem consumir,
    * só em contextos autorizados (ex.: risco/PLD, não marketing).
* Tudo é logado (quem pediu qual feature de quem, quando).

Mitiga:

* **OWASP A01/A05 (Broken Access Control / Security Misconfig)**,
* **ML03/ML04 (Model Inversion / Membership Inference)** — reduz exposição de features sensíveis que facilitam reidentificação.

### 4.3 Consistência Treino ↔ Produção (anti-skew)

* Mesma lógica de feature:

  * implementada **uma vez**, em pipelines versionados.
  * offline e online usam o **mesmo código** ou mesma função (lib interna).
* Point-in-time correctness:

  * offline features calculadas considerando apenas dados disponíveis até `t` (sem olhar futuro).
  * online lê do mesmo dataset materializado.
* Manifests:

  * cada feature batch é acompanhado de:

    * janela de dados,
    * versão de código,
    * hash dos insumos.

Mitiga:

* **ML08 — Model Skewing** (diferença de comportamento treino vs produção),
* Reduz risco de decisões erradas por divergência de feature.

### 4.4 DQ & Monitoramento de Features

* Regras específicas:

  * ranges esperados por feature,
  * taxa de nulos,
  * distribuição histórica (para detectar drift),
  * correlação suspeita com labels (ex.: vazamento de target).
* Em caso de anomalia:

  * marca feature como `degraded` ou `suspended`,
  * gatilha:

    * alerta no Z9,
    * possível rollback para versão anterior.

Mitiga:

* **Data/Concept Drift**, **ML01/ML02/ML10** (input manipulation / poisoning / model poisoning).

### 4.5 Supply Chain & Assinatura de Transformações

* Pipelines de feature engineering:

  * código versionado (Git),
  * analisado com SAST/Dependabot,
  * imagens de container assinadas (SLSA / cosign),
  * segredos via Vault.
* Artefatos de feature engineering (jobs, libs):

  * assinados digitalmente,
  * validados antes de rodar.

Mitiga:

* **ML06 — AI Supply Chain Attacks**,
* **NIST AI RMF / CSA AI Controls** sobre integridade da cadeia de ML.

---

## 5) Fluxo End-to-End (Narrativa Z2 → Z3 → Z4/Z5/Z6)

Conecta tudo que você já escreveu:

1. **Z2 (Raw)**:

   * dados brutos íntegros, versionados, imutáveis, com metadados & hashes.
2. **Z3-2.1/2.2/2.3/2.5**:

   * pipelines aplicam schema, DQ, regras de negócio, PII handling,
   * geram **Curated datasets confiáveis**.
3. **Z3-2.6 (Feature Store)**:

   * a partir dos Curated, criam **Feature Groups** governados,
   * registram no catálogo + registry,
   * aplicam DQ adicional + segurança por feature.
4. **Z4 (Model Factory)**:

   * treinos só consomem features oficiais (com lineage + DQ + metadados).
   * registram no **Model Registry (Z5)**:

     * quais Feature Groups e versões foram usados.
5. **Z5 (Model Registry)**:

   * só aprova modelos que usam features oficiais, com fonte clara.
6. **Z6 (Serving & LLM Gateway)**:

   * inferência só lê features da **Online Feature Store**,
   * e só carrega modelos **assinados e aprovados**,
   * tudo via Inference Gateway + IAM/Z8 + logs Z9.

Mensagem que você pode soltar na entrevista:

> “A Feature Store é o coração da segurança de ML: ela garante que os modelos sejam treinados e servidos com as mesmas features, derivadas apenas de dados curados e governados. Escrevem nela apenas pipelines assinados, leem apenas serviços autorizados, todas as features são versionadas, classificadas, auditadas e ligadas ao Model Registry. Isso é defesa de supply chain de ML na prática, não só no slide.”

---

## 6) Implementação no MLOps Security Lab (prático e pé-no-chão)

Você pode montar uma versão enxuta, mas conceitualmente correta:

1. **Feature Store Offline (simples)**

   * Criar tabelas em Postgres/ClickHouse ou Parquet:

     * `fs_offline_risco_cliente_v1`

       * colunas: `customer_id`, `event_ts`, `score_risco`, `avg_tx_30d`, `qtd_atrasos_12m`, etc.
   * Pipelines Airflow:

     * `build_fs_risco_cliente_v1`:

       * lê `curated_risco_transacoes_v2`, `curated_clientes_v3`,
       * calcula features,
       * aplica DQ,
       * grava tabela + manifest.

2. **Feature Store Online (mock realista)**

   * Subir um **serviço FastAPI + Redis/Postgres**:

     * endpoint interno `/features/risk/customer/{id}`,
     * consulta a tabela offline/materializada,
     * exige:

       * JWT mapeado a uma `service_account`,
       * mTLS entre Inference Gateway ↔ Feature Store.
   * Policies:

     * só serviços de scoring em Z6 podem chamar.

3. **Metadados & Catálogo**

   * Arquivos YAML em `feature_store/` descrevendo cada Feature Group:

     * usados tanto pela doc quanto pelos pipelines.
   * Gerar doc automático no README.

4. **Integração com Model Registry**

   * No registro de cada modelo (MLflow/whatever), adicionar:

     * `features: ["fs_offline_risco_cliente_v1@v1", "fs_offline_renda_estim_v2@v3"]`.

5. **Monitoramento**

   * Métricas:

     * latência do endpoint de features,
     * taxa de cache hit,
     * distribuição de `score_risco` ao longo do tempo (drift).
   * Logs:

     * quem pediu feature de qual `customer_id`,
     * volume por serviço.

---

## 7) Riscos mitigados (mapa mental rápido)

* **Data/Model Poisoning (ML02/ML10)**:
  Somente pipelines oficiais alimentam features; DQ + lineage + versionamento para detectar anomalias.
* **Train/Serving Skew (ML08)**:
  Lógica única, offline/online sincronizados, manifests, point-in-time correctness.
* **Model Inversion / Membership Inference (ML03/ML04)**:
  Acesso a features sensíveis restrito, mascaramento/tokenização, logs + ABAC.
* **Supply Chain Attacks (ML06)**:
  Código de features versionado, dependências auditadas, imagens e modelos assinados.
* **Compliance & PII**:
  Features herdam classificação de Z3; PII só entra como token/atributo permitido, com propósito claro.
