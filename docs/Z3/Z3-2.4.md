# Z3-2.4 — Data Catalog & Lineage

*(*se não está catalogado e rastreável, não existe para a plataforma*)*

A **Curated Zone (Z3)** só é realmente confiável quando você sabe **o que cada dataset é, de onde veio, quem cuida e como se transforma**. O **Data Catalog & Lineage** é o “Waze” da sua plataforma de dados/ML: mostra o mapa, o caminho percorrido e quem está trafegando por onde.

Princípio central:

> **Sem catálogo e lineage, Z3 vira um monte de tabelas soltas.
> Com catálogo e lineage, Z3 vira uma malha de dados governada, explicável e auditável.**

---

## 1) Objetivo

O módulo de **Data Catalog & Lineage** na Z3 existe para:

1. **Catalogar** todos os datasets, features e data products com metadados ricos.
2. **Mapear o fluxo de dados ponta a ponta**: Z0/Z1 → Z2 → Z3 → Z4/Z5/Z6 → Z7.
3. **Dar visibilidade e governança**:

   * Quem é dono?
   * Que dado é sensível?
   * Quais modelos/serviços dependem disso?
4. **Suportar auditoria, investigações e explicabilidade de modelos**:

   * “Essa decisão de crédito veio de onde, exatamente?”

---

## 2) O que é o Data Catalog na prática

Pensa no catálogo como um “**CMDB de dados e features**”.

Para cada **entidade relevante** (dataset, tabela, tópico, feature set, data product) o catálogo registra:

* **Identidade**

  * `name`: `curated_risco_transacoes_v2`
  * `tipo`: `table`, `view`, `feature_group`, `topic`
  * `zona`: `Z3` (curated/feature), com link para Z2/Z4/Z5/Z6 relacionados.

* **Descrição funcional**

  * O que representa?
  * Em que contexto é usado? (ex.: “Base oficial de transações de cartão para risco”)
  * Exemplos de queries / usos recomendados.

* **Metadados de governança**

  * `data_owner` (time dono),
  * `steward` (responsável operacional),
  * `criticality`: `low/medium/high/critical`,
  * `sla_freshness`: ex. `15m`, `D+1`.

* **Classificação & privacidade**

  * `sensitivity`: `public/internal/confidential/restricted`.
  * Flags:

    * `contains_pii`, `contains_financial_data`, `contains_credentials`.
  * Regras aplicáveis:

    * LGPD/GDPR, PCI, normas BACEN, etc.

* **Qualidade & Confiabilidade**

  * Link para:

    * relatórios de Data Quality (Z3-2.3),
    * indicadores de *freshness*,
    * status: `green / yellow / red`.

* **Acesso & políticas**

  * quais roles/ABAC podem ler,
  * se exige mTLS, VPN, etc.
  * links para as policies (Z8).

* **Dependências (lineage)**

  * quais tabelas/raw/streams alimentam esse dataset,
  * quais modelos (Z4/Z5) ou APIs (Z6/Z7) consomem.

No Lab, esse catálogo pode ser:

* Um **metastore + UI** (Amundsen, DataHub, OpenMetadata, etc.), ou
* Um **catálogo simplificado**:

  * diretório `catalog/` em YAML/JSON,
  * renderizado em Markdown no README,
  * com scripts que geram gráficos de lineage.

---

## 3) O que é Lineage (técnico + funcional)

**Lineage** responde duas perguntas:

1. **Upstream**: de onde veio este dado?

   * Quais buckets/pastas/tabelas em Z2 alimentam `curated_risco_transacoes_v2`?
   * Quais endpoints Z1 / fontes Z0 originam esses dados?
2. **Downstream**: quem depende deste dado?

   * Quais features (`feature_store.risco_ltv_v3`) derivam desta tabela?
   * Quais modelos (`model_risco_credito_v5`) usam essas features?
   * Quais APIs, relatórios, painéis e decisões de negócio consomem isso?

Lineage deve existir em **dois níveis**:

* **Técnico (fino)**:

  * colunas de entrada → colunas de saída,
  * jobs/dags, scripts, joins, filtros.
* **Funcional (de negócio)**:

  * “Transação considerada no cálculo de risco X vem de Y, segue tais regras, exclui Z, aplica tais limites.”

---

## 4) Como o Lineage é construído

No contexto do MLOps Security Lab, você constrói o lineage a partir de:

1. **Pipelines como código (Airflow, etc.)**

   * Cada DAG sabe:

     * de onde lê (Z2),
     * para onde escreve (Z3/Z4),
     * qual tarefa aplica qual transformação.
   * Essa informação é usada para gerar o grafo de lineage automaticamente.

2. **Metadados & manifests**

   * Cada run de pipeline grava um `manifest.json` com:

     * entradas (paths/hashes em Z2),
     * saídas (tabelas/partições em Z3),
     * versão do código (`git_sha`),
     * horário, volume, DQ report.

3. **Integração com o Catálogo**

   * Um job de *metadata ingestion* lê:

     * `schemas/`,
     * `manifests`,
     * DAGs,
     * Model Registry (Z5),
   * e monta o **grafo de dependências**:

     * visualizável em UI (mesmo que simples).

4. **Padrões de nome & IDs**

   * Uso consistente de:

     * `dataset_id`,
     * `model_id`,
     * `feature_id`,
     * `run_id`,
     * `request_id` / `correlation_id` (vindo da Z1).
   * Isso permite ligar:

     * requisição de um cliente → evento em Z1 → objeto em Z2 → linha em Z3 → feature em Z3 → predição em Z6 → decisão em Z7.

---

## 5) Segurança & Privacidade integradas ao Catálogo

O Catálogo não é só “wiki bonita”; é um **mecanismo de segurança e compliance**.

Como ele ajuda:

1. **Visibilidade de dados sensíveis**

   * Qualquer coluna com `pii=true` fica visível no catálogo.
   * Reguladores e segurança conseguem ver rapidamente:

     * onde estão CPFs, dados de cartão, segredos, etc.
   * Permite validar se PII está apenas onde deveria.

2. **Políticas dinâmicas (ABAC) guiadas pelo catálogo**

   * Policies do IAM/Z8 podem ler o catálogo:

     * “Se `dataset.sensitivity = 'restricted'`, só roles X e Y podem ler.”
     * “Se `column.contains_pii = true`, aplicar mascaramento automático.”

3. **Detecção de riscos de lineage**

   * Exemplo:

     * se um modelo de marketing usa dataset com `contains_pii=true` sem base legal → alerta.
     * se uma feature “score_marketing” depende de dados de PLD/FT → possível uso indevido.

4. **Explicabilidade & accountability**

   * Em uma decisão automatizada questionada (“Por que negaram meu crédito?”):

     * é possível navegar:

       * decisão → modelo (Z5) → versão → features → datasets Z3 → origens Z2/Z1/Z0,
       * mostrando que:

         * dados vieram de fontes oficiais,
         * passaram por DQ,
         * seguiram políticas de privacidade.

---

## 6) Implementação no MLOps Security Lab (prático e didático)

Você não precisa levantar um DataHub completo agora, mas pode mostrar conceitos de forma clara:

1. **Estrutura de Catálogo em Código**

   * Pasta `catalog/` com arquivos como:

     * `catalog/curated_risco_transacoes_v2.yaml`
     * `catalog/feature_risco_score_v1.yaml`
   * Cada arquivo com:

     * descrição,
     * owner,
     * zona,
     * sensibilidade,
     * origem (refs Z2),
     * consumidores (models/APIs).

2. **Geração de Documentação Automática**

   * Script que lê os YAMLs e gera:

     * uma página Markdown ou HTML com:

       * tabelas de datasets,
       * colunas,
       * classificações,
       * lineage simplificado.
   * Referenciar no README principal.

3. **Lineage Simplificado**

   * Em cada pipeline (Airflow), registrar:

     * `upstream_datasets`,
     * `downstream_datasets`.
   * Gerar um grafo (ex.: usando `mermaid`):

     ```mermaid
     graph LR
       Z2_raw_transacoes --> curated_risco_transacoes_v2 --> feature_risco_score_v1 --> model_risco_credito_v5 --> api_risco_credito
     ```
   * Isso mostra visualmente a dependência ponta a ponta.

4. **Controles de Acesso guiados pelo Catálogo**

   * Exemplo de política (em pseudo YAML):

     ```yaml
     policy: allow_read_curated_risco_transacoes_v2
     when:
       role in ["risk_analyst", "ml_engineer_risk"]
       and dataset.sensitivity in ["confidential", "restricted"]
     ```

---

## 7) Riscos mitigados (conectando com Z3 Seção 3)

Data Catalog & Lineage atacam diretamente:

* **3.1 — Dados incorretos sem dono**

  * Cada dataset tem owner + DQ + documentação.
* **3.2 — Vazamento de PII**

  * Sensibilidade e localização de PII são conhecidos e gerenciados.
* **3.3 — Leakage & uso indevido**

  * Lineage mostra se uma feature/modelo está usando dado que não deveria.
* **3.4 — Bypass da Z3**

  * Qualquer consumo direto de Z2 fica evidente porque não aparece como “data product” oficial no catálogo.
* **3.5 — Falta de transparência**

  * Lineage + catálogo dão narrativa clara do fluxo de dados.
* **3.6 — Supply chain de features/modelos**

  * Você sabe quais fontes alimentam quais modelos; se um dataset for comprometido, sabe quais modelos revisar.

---

## 8) Alinhamento com Frameworks

* **NIST SP 800-53**

  * **PL-8, PM-5, PM-11** — Inventário e responsabilidade por recursos de informação.
  * **AU-6, AU-12** — Logs e trilhas de auditoria conectadas ao lineage.
* **NIST AI RMF**

  * **Govern / Map / Measure** — transparência, accountability, data & model lineage.
* **CSA Cloud Controls Matrix / CSA AICM**

  * **DSI** (Data Security & Information Lifecycle),
  * **GRC** (Governance, Risk & Compliance),
  * **AIS** (AI Security & Integrity) — exige rastreabilidade da cadeia de dados/modelos.
* **OWASP ML / LLM Top 10**

  * Lineage & catálogo ajudam a mitigar:

    * data poisoning,
    * training data leakage,
    * insecure plugin/tooling data flows.

---

## 9) Frase pronta pra levar pra entrevista

Se quiser resumir em 20 segundos:

> “Na camada Z3 eu trato o catálogo e o lineage como parte da segurança e da governança.
> Cada dataset e feature é um produto com dono, contrato de schema, regras de qualidade, classificação de dados e links explícitos para suas fontes em Z2 e para os modelos em Z4/Z5/Z6.
> Isso me permite saber exatamente de onde vem cada informação usada numa decisão, detectar usos indevidos de PII, reagir rápido a incidentes de data poisoning e provar para o regulador como o meu pipeline de IA é controlado de ponta a ponta.”
