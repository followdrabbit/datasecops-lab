# 2.7 ETL / Streaming / MQ (Conectores Oficiais)

Depois que a requisição passou por **todos os controles da Z1**
(WAF → AuthN/AuthZ → Content Validation → Anti-malware/CDR → Higiene inicial),
ainda falta responder:

> “**Quem**, exatamente, está autorizado a levar esses dados até o Raw Data Lake (Z2)?”

A resposta correta numa arquitetura segura (e no Lab) é:

> **Só conectores oficiais, autenticados, versionados e observáveis.**

Nada de app externo escrevendo direto no MinIO.
Nada de script manual com credencial hardcoded apontando pro bucket de Raw.

---

## 2.7.1 Papel desses conectores

Os componentes de **ETL / Streaming / MQ** na Z1 fazem três coisas:

1. **Desacoplar ingestão externa** da escrita interna.
2. **Padronizar o caminho de entrada em Z2**.
3. **Aplicar identidade técnica controlada** (service accounts, Vault, policies).

Eles transformam:

> requisições aprovadas / arquivos validados / eventos recebidos

em:

> gravações seguras na **Z2 — Raw Data Lake (Restricted)**.

---

## 2.7.2 Formas comuns de conectores oficiais

Você pode implementar isso com diferentes padrões (todos válidos, se governados):

1. **Jobs ETL (batch)**

   * Ex.: DAGs do **Airflow**.
   * Lêem dados:

     * de uma área de staging segura,
     * de uma API interna do gateway,
     * de uma fila/tópico.
   * Escrevem:

     * em buckets de Raw (MinIO),
     * em tabelas brutas (Postgres, etc.).

2. **Streaming / Mensageria**

   * Ex.: Kafka, RabbitMQ, NATS, SQS, etc.
   * Z1 publica mensagens validadas em:

     * **tópicos oficiais de ingestão**.
   * Conectores internos (consumidores autorizados) leem desses tópicos e gravam em Z2.
   * Bom para:

     * alto volume,
     * desacoplamento forte,
     * replay.

3. **Microserviços internos de ingestão**

   * Serviços internos (FastAPI, etc.) que:

     * recebem chamadas do gateway,
     * aplicam as regras finais,
     * gravam em Z2.
   * Sempre:

     * em rede interna,
     * com autenticação via service account,
     * sem exposição pública.

**Ponto comum entre todos:**

* São **oficiais**, versionados, configurados via infraestrutura como código, com policies claras.
* Usam segredos seguros (Vault), não credenciais improvisadas.

---

## 2.7.3 O que significa “Somente conectores oficiais podem persistir em Z2”

É uma regra arquitetural, importante o suficiente para virar frase de efeito:

> “**Proibido** escrever direto na Raw Zone sem passar por um conector oficial da Z1.”

Na prática, quer dizer:

* MinIO/Postgres de Z2:

  * só aceitam gravação:

    * de hosts internos específicos,
    * de service accounts específicas,
    * via caminhos/tabelas definidos.
* Esses service accounts:

  * pertencem aos jobs/serviços de ETL/streaming,
  * são gerenciados por Vault/IdP,
  * têm permissões **mínimas necessárias**.

Nada de:

* chave root do MinIO num script aleatório,
* credencial do banco colada em pipeline GitHub Actions público,
* desenvolvedor apontando notebook direto pra Raw em produção.

---

## 2.7.4 Fluxos típicos (para visualizar)

### Fluxo 1 — Upload HTTP → Raw (via ETL)

1. Cliente/parceiro manda arquivo para `/ingest/...`.
2. WAF + AuthN/AuthZ + validações + scan → OK.
3. Arquivo cai numa **área de staging interna** (não é Z2 ainda).
4. DAG do Airflow (conector oficial):

   * roda periodicamente ou sob evento,
   * lê staging,
   * faz checagens leves adicionais (se quiser),
   * grava o arquivo tratado/registrado em **Z2 — Raw Zone** com:

     * path padronizado,
     * metadata (fonte, timestamp, etc.).
5. Staging é limpo/quarentenado conforme política.

### Fluxo 2 — Eventos / JSON → Raw (via fila/tópico)

1. API de ingestão recebe JSON validado.
2. Publica mensagem em um **tópico oficial** (ex.: `raw.transacoes.ingest`).
3. Um consumer interno (serviço ou job) lê desse tópico:

   * autenticado,
   * com permissão só naquele tópico,
   * grava eventos em Z2 como arquivo de log ou tabela bruta.
4. Tudo fica rastreável:

   * fonte → tópico → consumer → Z2.

---

## 2.7.5 Benefícios de usar conectores oficiais

1. **Desacoplamento**

   * Se o formato externo mudar, você adapta o conector — não o data lake inteiro.
2. **Centralização de políticas**

   * Todos os conectores seguem:

     * mesmas políticas de segurança,
     * mesmo padrão de logging/auditoria.
3. **Rastreabilidade**

   * Dá pra responder:

     * “Esse dado chegou por qual endpoint?”
     * “Qual job escreveu esse arquivo em Raw?”
4. **Menos risco de bypass**

   * Como só os conectores têm credenciais de escrita:

     * reduzir chance de alguém “dropar” coisa direto em Z2 fora das regras.

---

## 2.7.6 Implementação prática no Lab

No **MLOps Security Lab**, você pode:

* Usar **Airflow** como principal “conector oficial”:

  * DAGs que:

    * leem arquivos aceitos,
    * gravam no MinIO (Z2),
    * registram metadados (fonte, hash, hora).
* Proteger MinIO/Postgres com:

  * credenciais armazenadas no **Vault**,
  * políticas por bucket/banco/tabela.
* Fazer os serviços de ingestão internos:

  * rodarem em rede interna,
  * só acessíveis via gateway.
* Deixar claro na documentação:

  * quais serviços/DAGs são “oficiais”.
  * qualquer escrita direta em Z2 fora deles = violação de arquitetura.

---

## 2.7.7 Anti-patterns (o que você quer evitar)

Vale listar pra fixar (e falar na entrevista, se vier):

* Aplicação externa escrevendo direto no MinIO/Postgres de Raw.
* Script/manual de analista jogando CSV em pasta de Raw “porque é mais rápido”.
* Conector sem autenticação forte, usando usuário “genérico” compartilhado.
* Pipelines de CI/CD empurrando dado diretamente em Z2 pra “testar modelo”.

Tudo isso quebra:

* trilha de auditoria,
* confiança no dado,
* isola a Z1,
* piora risco de data poisoning e incidente.
