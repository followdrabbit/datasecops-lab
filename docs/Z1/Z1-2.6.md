# 2.6 Data Quality & Anomaly Checks (Higiene inicial)

Depois de:

1. passar pelo **WAF** (ataques óbvios),
2. ser **autenticado/autorizado** (sabemos quem é),
3. ter o **conteúdo validado** (tipo/tamanho/schema),
4. e, se for arquivo, passar por **Anti-malware/CDR**,

entra uma camada leve, mas estratégica:

> **Higiene de dados na borda** — checagens simples para evitar que lixo evidente, erro grosseiro ou padrão ridículo entre no Raw Data Lake (Z2) como se fosse “dado bom”.

Não é feature engineering.
Não é detecção estatística avançada.
É “sanidade mínima” para não envenenar o lago logo na chegada.

---

## 2.6.1 Objetivo

Essa etapa responde:

* “Esse lote faz sentido minimamente?”
* “Tem alguma coisa tão errada que não deveria nem entrar em Z2?”
* “Tem algo estranho o suficiente pra marcar como suspeito/quarentena/log especial?”

Ela reduz:

* retrabalho para times de dados,
* chance de data poisoning acidental,
* impacto de bugs em sistemas fontes,
* risco de decisions de negócio serem baseadas em dado obviamente inválido.

---

## 2.6.2 Tipos de checagens (o que entra aqui)

Essas checagens são **rule-based, simples e baratas**, aplicadas logo após a validação de conteúdo.

Alguns tipos típicos:

1. **Campos críticos não nulos**

   * Ex.: `id_transacao`, `id_cliente`, `timestamp`, `valor`.
   * Se esses campos vêm vazios ou nulos em massa → algo errado.

2. **Ranges plausíveis**

   * Ex.:

     * `valor >= 0` (ou > 0),
     * `idade` entre 0 e 120,
     * `score` entre 0 e 1000,
     * `data_hora` não está 30 anos no futuro.
   * Não é “regra de negócio complexa”, é só “não parece impossível”.

3. **Domínios conhecidos (enums)**

   * Ex.: `canal ∈ {APP, WEB, ATM}`, `status ∈ {APROVADO, NEGADO, PENDENTE}`.
   * Se começa a vir `status = OK` ou `canal = MOBILEAPPV2` sem estar no contrato → suspeito.

4. **Consistência estrutural por lote**

   * Mesma quantidade de colunas em todas as linhas (CSV),
   * mesmo tipo de dado por coluna,
   * nenhuma linha totalmente vazia,
   * proporção de registros inválidos abaixo de um limiar.

5. **Checks simples de unicidade ou chave**

   * Ex.: `id_transacao` duplicado demais no mesmo lote.
   * Não precisa ser super rígido, mas pode sinalizar.

---

## 2.6.3 Exemplos concretos

### Exemplo 1 — Lote de transações

Regras simples para `/ingest/transacoes`:

* `id_transacao` não pode ser vazio.
* `valor > 0`.
* `data_hora`:

  * não no futuro além de X minutos,
  * não anterior a ano 2000, por exemplo.
* `canal` em lista conhecida.

Política possível:

* Se 1–2 registros quebram regra:

  * marca como erro de linha,
  * joga esses registros em “quarentena” ou log de rejeição.
* Se 80%+ do lote quebra regra:

  * rejeita o lote inteiro (parece bug na origem),
  * alerta.

### Exemplo 2 — CSV de cadastro

* Cabeçalho ok,
* mas:

  * `cpf` vazio em 60%,
  * `email` todos `"teste@teste.com"`,
  * `data_nascimento` = `2025-01-01` pra todo mundo.

Pode não ser ataque, mas é **forte sinal de dado fake ou ambiente errado** → marcar, segregar, não tratar como dado confiável.

---

#### 2.6.4 Anomalias: bloquear x aceitar com alerta

Aqui entram duas classes de ação:

1. **Bloqueio imediato (hard fail)**:

   * Violação massiva de regras básicas:

     * lote quase todo inválido,
     * tipos completamente fora,
     * datas absurdas em massa,
     * valores negativos onde não deveria existir nunca.
   * Indica:

     * bug grave,
     * uso errado do endpoint,
     * potencial data poisoning grosseiro.

2. **Aceita com alerta / quarentena (soft fail)**:

   * Poucos registros problemáticos,
   * padrões estranhos, mas não conclusivos.
   * Ações:

     * isolar registros suspeitos em área de quarentena,
     * log detalhado,
     * gerar alerta para revisão.

A decisão depende:

* criticidade da fonte,
* contexto de negócio,
* maturidade do ambiente.

No lab, o mais importante é mostrar que **você pensa nisso**.

---

## 2.6.5 Onde essa etapa se encaixa no fluxo Z1

Fluxo típico completo:

1. Chega requisição / lote.
2. **WAF** filtra ataques genéricos.
3. **AuthN/AuthZ** garante identidade/escopo.
4. **Content Validation**:

   * tipo, tamanho, schema básico.
5. **Anti-malware/CDR** (se houver arquivos).
6. **Data Quality & Anomaly Checks (Higiene)**:

   * regras simples de sanidade.
   * decisão:

     * ok → segue para ETL/MQ → Z2 (Raw).
     * parcialmente ok → segue + quarentena + alerta.
     * bizarro → rejeita + log + alerta.

Ou seja: é a última linha de defesa da borda antes do **Raw Data Lake**.

---

## 2.6.6 Implementação prática no Lab

Você pode mostrar essa etapa com coisas bem tangíveis:

* **No serviço de ingestão (FastAPI, por exemplo)**:

  * após validar o schema:

    * rodar funções simples de sanidade (ex.: `if valor <= 0: marcar erro`).
  * montar resposta:

    * quantos registros aceitos,
    * quantos rejeitados.

* **No Airflow (ETL inicial)**:

  * tasks de validação:

    * checar percentuais inválidos,
    * se passar do threshold → falhar DAG ou enviar alerta.
    * registrar arquivos/linhas inválidas em uma pasta de “quarentena”.

* **No logging**:

  * logar:

    * fonte,
    * número de registros inválidos,
    * tipo de erro,
    * id do lote.

Isso aproxima o lab de uma operação real: não é só “subir serviços”, é mostrar o raciocínio de higiene.

---

## 2.6.7 Boas práticas para essa camada

* **Simples, mas explícito**:

  * regras documentadas,
  * nada implícito “na cabeça do dev”.
* **Fail fast, mas inteligente**:

  * evitar bloquear por ruído mínimo,
  * bloquear quando é claramente problema estrutural.
* **Telemetria**:

  * acompanhar evolução de erros:

    * se uma fonte começa a errar demais, algo quebrou.
* **Integração com contrato de dados (Z0)**:

  * Data Quality & Anomaly Checks devem refletir o que foi combinado com a fonte.
* **Segurança**:

  * não logar payload sensível inteiro,
  * mas logar o suficiente para entender padrões de erro/suspeita.
